#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡æ›¿æ¢JSONæ–‡ä»¶ä¸­çš„å­—æ®µåè„šæœ¬
ç”¨äºå°†é•¿ä¸­æ–‡å­—æ®µåæ›¿æ¢ä¸ºç®€æ´çš„è‹±æ–‡å­—æ®µå
"""

import json
import os
from typing import Dict, List, Any

def load_json_file(file_path: str) -> List[Dict[str, Any]]:
    """
    è¯»å–JSONæ–‡ä»¶
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        
    Returns:
        è§£æåçš„JSONæ•°æ®åˆ—è¡¨
        
    Raises:
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
        json.JSONDecodeError: JSONæ ¼å¼é”™è¯¯
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            print(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶: {file_path}")
            print(f"ğŸ“Š æ•°æ®æ¡æ•°: {len(data)}")
            return data
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
        raise
    except json.JSONDecodeError as e:
        print(f"âŒ é”™è¯¯: JSONæ ¼å¼é”™è¯¯ - {e}")
        raise

def create_reverse_mapping(field_mapping: Dict[str, str]) -> Dict[str, str]:
    """
    åˆ›å»ºåå‘æ˜ å°„ï¼ˆä»æ—§å­—æ®µååˆ°æ–°å­—æ®µåï¼‰
    
    Args:
        field_mapping: æ–°å­—æ®µååˆ°æ—§å­—æ®µåçš„æ˜ å°„
        
    Returns:
        æ—§å­—æ®µååˆ°æ–°å­—æ®µåçš„æ˜ å°„
    """
    reverse_mapping = {old_key: new_key for new_key, old_key in field_mapping.items()}
    print(f"ğŸ”„ åˆ›å»ºäº† {len(reverse_mapping)} ä¸ªå­—æ®µæ˜ å°„å…³ç³»")
    return reverse_mapping

def transform_record_structure(record: Dict[str, Any], content_field_mapping: Dict[str, str]) -> Dict[str, Any]:
    """
    è½¬æ¢å•æ¡è®°å½•çš„ç»“æ„ï¼Œå®ç°åµŒå¥—åŒ–å’Œå­—æ®µé‡å‘½å
    
    Args:
        record: åŸå§‹è®°å½•å­—å…¸
        content_field_mapping: å†…å®¹å­—æ®µæ˜ å°„å…³ç³»ï¼ˆæ—§->æ–°ï¼‰
        
    Returns:
        è½¬æ¢åçš„æ–°è®°å½•ç»“æ„
    """
    new_record = {}
    content = {}
    renamed_count = 0
    
    for old_key, value in record.items():
        # 1. åˆ é™¤"ç¼–å·"å­—æ®µ
        if old_key == "ç¼–å·":
            continue
            
        # 2. åŸºæœ¬ä¿¡æ¯å­—æ®µå¤„ç†
        elif old_key == "Q1æ–‡æœ¬ç¼–å·":
            new_record["dialog_id"] = value
            renamed_count += 1
        elif old_key == "æäº¤äºº":
            new_record["user_id"] = value
            renamed_count += 1
            
        # 3. å†…å®¹ç›¸å…³å­—æ®µæ”¾å…¥contentä¸­
        elif old_key in content_field_mapping:
            new_key = content_field_mapping[old_key]
            content[new_key] = value
            renamed_count += 1
        else:
            # 4. å…¶ä»–æœªæ˜ å°„çš„å­—æ®µä¹Ÿæ”¾å…¥contentä¸­ï¼ˆä¿é™©èµ·è§ï¼‰
            content[old_key] = value
    
    # 5. æ·»åŠ å›ºå®šçš„eval_schema_id
    new_record["eval_schema_id"] = "sympathy_positive"
    
    # 6. æ·»åŠ contentå­—æ®µ
    if content:
        new_record["content"] = content
    
    return new_record, renamed_count

def batch_transform_data(data: List[Dict[str, Any]], content_field_mapping: Dict[str, str]) -> List[Dict[str, Any]]:
    """
    æ‰¹é‡è½¬æ¢æ‰€æœ‰è®°å½•çš„æ•°æ®ç»“æ„
    
    Args:
        data: åŸå§‹æ•°æ®åˆ—è¡¨
        content_field_mapping: å†…å®¹å­—æ®µæ˜ å°„å…³ç³»ï¼ˆæ—§->æ–°ï¼‰
        
    Returns:
        ç»“æ„å·²è½¬æ¢çš„æ•°æ®åˆ—è¡¨
    """
    new_data = []
    total_transformed = 0
    
    for i, record in enumerate(data):
        new_record, transformed_count = transform_record_structure(record, content_field_mapping)
        new_data.append(new_record)
        total_transformed += transformed_count
        
        if (i + 1) % 5 == 0:  # æ¯5æ¡è®°å½•æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            print(f"ğŸ”„ å·²å¤„ç† {i + 1}/{len(data)} æ¡è®°å½•")
    
    print(f"âœ… æ‰¹é‡æ•°æ®è½¬æ¢å®Œæˆ!")
    print(f"ğŸ“Š æ€»å…±è½¬æ¢äº† {total_transformed} ä¸ªå­—æ®µ")
    print(f"ğŸ“‹ æ·»åŠ äº† {len(data)} ä¸ª eval_schema_id å­—æ®µ")
    return new_data

def save_json_file(data: List[Dict[str, Any]], output_path: str) -> None:
    """
    ä¿å­˜JSONæ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    try:
        with open(output_path, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=2)
        print(f"âœ… æˆåŠŸä¿å­˜åˆ°: {output_path}")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        raise

def print_sample_comparison(original_data: List[Dict[str, Any]], 
                          new_data: List[Dict[str, Any]], 
                          sample_index: int = 0) -> None:
    """
    æ‰“å°æ ·æœ¬å¯¹æ¯”ï¼Œæ˜¾ç¤ºæ•°æ®ç»“æ„è½¬æ¢å‰åçš„å·®å¼‚
    
    Args:
        original_data: åŸå§‹æ•°æ®
        new_data: è½¬æ¢åçš„æ•°æ®
        sample_index: è¦æ˜¾ç¤ºçš„æ ·æœ¬ç´¢å¼•
    """
    if sample_index >= len(original_data):
        return
        
    print("\n" + "="*50)
    print("ğŸ“‹ æ•°æ®ç»“æ„è½¬æ¢å¯¹æ¯”ç¤ºä¾‹")
    print("="*50)
    
    original_sample = original_data[sample_index]
    new_sample = new_data[sample_index]
    
    print("ğŸ”¸ åŸå§‹æ•°æ®ç»“æ„:")
    print(f"  - æ€»å­—æ®µæ•°: {len(original_sample)}")
    print(f"  - åŒ…å«å­—æ®µ: {list(original_sample.keys())[:3]}... (æ˜¾ç¤ºå‰3ä¸ª)")
    
    print("\nğŸ”¹ è½¬æ¢åæ•°æ®ç»“æ„:")
    print(f"  - eval_schema_id: {new_sample.get('eval_schema_id')}")
    print(f"  - dialog_id: {new_sample.get('dialog_id')}")
    print(f"  - user_id: {new_sample.get('user_id')}")
    
    if 'content' in new_sample:
        content_keys = list(new_sample['content'].keys())
        print(f"  - contentå­—æ®µåŒ…å« {len(content_keys)} ä¸ªå­å­—æ®µ:")
        print(f"    {content_keys[:3]}... (æ˜¾ç¤ºå‰3ä¸ª)")
    
    print("\nâœ¨ ä¸»è¦å˜åŒ–:")
    print("  âœ… åˆ é™¤äº† 'ç¼–å·' å­—æ®µ")
    print("  âœ… æ·»åŠ äº† 'eval_schema_id' å­—æ®µ")
    print("  âœ… 'Q1æ–‡æœ¬ç¼–å·' â†’ 'dialog_id'")
    print("  âœ… 'æäº¤äºº' â†’ 'user_id'")
    print("  âœ… è¯„ä¼°ç›¸å…³å­—æ®µåµŒå¥—åˆ° 'content' ä¸­")

def main():
    """
    ä¸»å‡½æ•° - æ‰§è¡Œæ‰¹é‡æ•°æ®ç»“æ„è½¬æ¢æµç¨‹
    """
    print("ğŸš€ å¼€å§‹æ‰¹é‡è½¬æ¢JSONæ•°æ®ç»“æ„")
    print("="*50)
    
    # å†…å®¹å­—æ®µæ˜ å°„å…³ç³»ï¼ˆä¸¥æ ¼æŒ‰ç…§æ‚¨æä¾›çš„æ˜ å°„ - æ–°å­—æ®µå -> æ—§å­—æ®µåï¼‰
    CONTENT_FIELD_MAPPING = {
        "round5_need_positive_attention": "Q2æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬5è½®å¯¹è¯ä¸­æ˜¯å¦éœ€è¦ä½¿ç”¨ç§¯æå…³æ³¨çš„æŠ€æœ¯ï¼Ÿ",
        "round5_used_positive_attention": "Q3æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬5è½®ä¸­çš„å›å¤ï¼Œæ˜¯å¦ä½¿ç”¨äº†ç§¯æå…³æ³¨çš„æŠ€æœ¯ï¼Ÿ",
        "round5_positive_attention_example": "Q3-1æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯é‡Œï¼Œæ•™ç»ƒåœ¨ç¬¬5è½®å¯¹è¯ä¸­åº”è¯¥å¦‚ä½•ä»æ­£å‘è§’åº¦åé¦ˆæ¥è®¿è€…æåŠçš„æ„Ÿå—ï¼Œæƒ³æ³•æˆ–è€…è¡Œä¸ºï¼Ÿè¯·æ ¹æ®è¯¥è§’åº¦æä¾›ä¸€ä¸ªæ­£å‘åé¦ˆçš„èŒƒä¾‹ã€‚",
        "round5_need_empathy": "Q4æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬5è½®å¯¹è¯ä¸­æ˜¯å¦éœ€è¦å…±æƒ…ï¼Ÿ",
        "round5_empathy_target_needed": "Q4-1æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬5è½®å¯¹è¯ä¸­éœ€è¦å…±æƒ…çš„å¯¹è±¡æ˜¯ï¼Ÿ",
        "round5_has_empathy": "Q5æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬5è½®ä¸­çš„å›å¤ï¼Œæ˜¯å¦å­˜åœ¨å…±æƒ…ï¼Ÿ",
        "round5_empathy_target_actual": "ç¬¬5è½®å…±æƒ…å¯¹è±¡æ˜¯ï¼Ÿ",
        "round5_empathy_target_accuracy": "Q5-2è¯·é—®æ•™ç»ƒåœ¨ç¬¬5è½®ä¸­ï¼Œå…±æƒ…å¯¹è±¡æ˜¯å¦å‡†ç¡®ï¼Ÿ",
        "round5_empathy_consistency": "ç¬¬5è½®å…±æƒ…æ˜¯å¦åŒ¹é…",
        "round5_empathy_mismatch_reason": "ç¬¬5è½®å…±æƒ…ä¸åŒ¹é…åŸå› ",
        "round5_empathy_depth": "ç¬¬5è½®å…±æƒ…ç¨‹åº¦æ˜¯å¦å‡†ç¡®ï¼Ÿ",
        "round5_empathy_improvement": "Q5-5è¯·é—®æ•™ç»ƒåœ¨ç¬¬5è½®ä¸­åº”è¯¥å¦‚ä½•å›å¤ï¼Œå…±æƒ…ç¨‹åº¦æ‰æ˜¯åˆé€‚çš„ï¼Ÿè¯·æä¾›ä¸€ä¸ªæ‚¨è®¤ä¸ºåˆé€‚çš„å›å¤èŒƒä¾‹ã€‚",
        "round10_need_positive_attention": "Q6æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬10è½®å¯¹è¯ä¸­æ˜¯å¦éœ€è¦ä½¿ç”¨ç§¯æå…³æ³¨çš„æŠ€æœ¯ï¼Ÿ",
        "round10_used_positive_attention": "Q7æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬10è½®ä¸­çš„å›å¤ï¼Œæ˜¯å¦ä½¿ç”¨äº†ç§¯æå…³æ³¨çš„æŠ€æœ¯ï¼Ÿ",
        "round10_positive_attention_example": "Q7-1æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯é‡Œï¼Œæ•™ç»ƒåœ¨ç¬¬10è½®å¯¹è¯ä¸­åº”è¯¥å¦‚ä½•ä»æ­£å‘è§’åº¦åé¦ˆæ¥è®¿è€…æåŠçš„æ„Ÿå—ï¼Œæƒ³æ³•æˆ–è€…è¡Œä¸ºï¼Ÿè¯·æ ¹æ®è¯¥è§’åº¦æä¾›ä¸€ä¸ªæ­£å‘åé¦ˆçš„èŒƒä¾‹ã€‚",
        "round10_need_empathy": "Q8æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬10è½®å¯¹è¯ä¸­æ˜¯å¦éœ€è¦å…±æƒ…ï¼Ÿ",
        "round10_empathy_target_needed": "Q8-1æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬10è½®å¯¹è¯ä¸­éœ€è¦å…±æƒ…çš„å¯¹è±¡æ˜¯ï¼Ÿ",
        "round10_has_empathy": "Q9æ‚¨è§‰å¾—è¿™ç»„å¯¹è¯ä¸­ï¼Œæ•™ç»ƒåœ¨ç¬¬10è½®ä¸­çš„å›å¤ï¼Œæ˜¯å¦å­˜åœ¨å…±æƒ…ï¼Ÿ",
        "round10_empathy_target_actual": "Q9-1è¯·é—®æ•™ç»ƒåœ¨ç¬¬10è½®ä¸­ï¼Œå®é™…å›å¤çš„å…±æƒ…å¯¹è±¡æ˜¯ï¼Ÿ",
        "round10_empathy_target_accuracy": "Q9-2è¯·é—®æ•™ç»ƒåœ¨ç¬¬10è½®ä¸­ï¼Œå…±æƒ…å¯¹è±¡æ˜¯å¦å‡†ç¡®ï¼Ÿ",
        "round10_empathy_consistency": "Q9-3è¯·é—®æ•™ç»ƒåœ¨ç¬¬10è½®ä¸­çš„å›å¤ï¼Œæ•™ç»ƒçš„å…±æƒ…å›å¤å’Œæ¥è®¿è€…æƒ…ç»ªæ˜¯å¦ä¸€è‡´ï¼Ÿ",
        "round10_empathy_consistency_supplement": "Q9-3è¯·é—®æ•™ç»ƒåœ¨ç¬¬10è½®ä¸­çš„å›å¤ï¼Œæ•™ç»ƒçš„å…±æƒ…å›å¤å’Œæ¥è®¿è€…æƒ…ç»ªæ˜¯å¦ä¸€è‡´ï¼Ÿ-ä¸ä¸€è‡´-è¡¥å……å†…å®¹",
        "round10_empathy_depth": "Q9-4è¯·é—®æ•™ç»ƒåœ¨ç¬¬10è½®ä¸­çš„å›å¤ï¼Œæ•™ç»ƒå›å¤çš„å…±æƒ…ç¨‹åº¦æ˜¯ï¼Ÿ",
        "round10_empathy_depth_supplement": "å¦‚æœå…±æƒ…ç¨‹åº¦é€‰æ‹©å…¶ä»–ï¼Œè¯·è¡¥å……è¯´æ˜",
        "round10_empathy_improvement": "Q9-5è¯·é—®æ•™ç»ƒåœ¨ç¬¬10è½®ä¸­åº”è¯¥å¦‚ä½•å›å¤ï¼Œå…±æƒ…ç¨‹åº¦æ‰æ˜¯åˆé€‚çš„ï¼Ÿè¯·æä¾›ä¸€ä¸ªæ‚¨è®¤ä¸ºåˆé€‚çš„å›å¤èŒƒä¾‹ã€‚",
        "remarks": "å¤‡æ³¨"
    }
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    INPUT_FILE = "zhang-junjie-sympathy.json"
    OUTPUT_FILE = "zhang-junjie-sympathy-transformed.json"
    
    try:
        # 1. è¯»å–åŸå§‹JSONæ–‡ä»¶
        original_data = load_json_file(INPUT_FILE)
        
        # 2. åˆ›å»ºåå‘æ˜ å°„ï¼ˆæ—§å­—æ®µå->æ–°å­—æ®µåï¼‰
        content_mapping = create_reverse_mapping(CONTENT_FIELD_MAPPING)
        
        # 3. æ‰¹é‡è½¬æ¢æ•°æ®ç»“æ„
        new_data = batch_transform_data(original_data, content_mapping)
        
        # 4. æ˜¾ç¤ºè½¬æ¢å¯¹æ¯”ç¤ºä¾‹
        print_sample_comparison(original_data, new_data)
        
        # 5. ä¿å­˜æ–°æ–‡ä»¶
        save_json_file(new_data, OUTPUT_FILE)
        
        print("\n" + "="*50)
        print("ğŸ‰ æ‰¹é‡æ•°æ®ç»“æ„è½¬æ¢å®Œæˆ!")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {INPUT_FILE}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
        print("="*50)
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main()) 